{"version":3,"file":"js/406.d74229d1.js","mappings":"6MAAIA,EAAIC,OAAOC,eACXC,EAAIA,CAACC,EAAGC,EAAGC,IAAMD,KAAKD,EAAIJ,EAAEI,EAAGC,EAAG,CAAEE,YAAY,EAAIC,cAAc,EAAIC,UAAU,EAAIC,MAAOJ,IAAOF,EAAEC,GAAKC,EACzGK,EAAIA,CAACP,EAAGC,EAAGC,KAAOH,EAAEC,EAAe,iBAALC,EAAgBA,EAAI,GAAKA,EAAGC,GAAIA,GAKlE,MAAMM,EACJC,WAAAA,GACEF,EAAEG,KAAM,gBACRH,EAAEG,KAAM,cAAe,SACvBH,EAAEG,KAAM,gBAAiB,OACzBC,QAAQC,IAAI,4BACd,CACA,kBAAIC,GACF,GAA2B,QAAvBH,KAAKI,cACP,MAAO,+HACT,CACE,MAAQC,SAAUd,EAAGe,KAAMd,GAAMe,OAAOC,SACxC,MAAQ,GAAEjB,MAAMC,gGAClB,CACF,CACA,4BAAMiB,GACJ,MAAMlB,QAAUmB,EAAAA,gBAAkBC,eAChC,oEAEFX,KAAKY,mBAAqBF,EAAAA,GAAeG,kBAAkBtB,EAAG,CAC5DuB,YAAa,CACXX,eAAgBH,KAAKG,eACrBY,SAAU,OAEZC,YAAahB,KAAKgB,aAEtB,CACA,gBAAMC,SACEjB,KAAKS,yBACX,MAAMlB,QAAU2B,EAAAA,EAAAA,WACVlB,KAAKmB,OAAO,CAAEC,MAAO7B,GAC7B,CACA,YAAM4B,CAAO5B,GACX,MAAMC,GAAI6B,EAAAA,EAAAA,GAAE9B,GACZ,QAA0B,IAAtBS,KAAKY,aACP,MAAO,CAAEU,aAAS,EAAQC,UAAW,GAAIC,WAAYhC,GACvD,MAAMiC,EAAIzB,KAAKY,aAAaO,OAAO3B,GAAGkC,WACtC,GAAiB,IAAbD,EAAEE,OACJ,MAAO,CAAEL,aAAS,EAAQC,UAAW,GAAIC,WAAYhC,GACvD,MAAMoC,EAAIH,EAAE,GACZ,YAAyB,IAAlBG,EAAEC,YAAyB,CAAEP,aAAS,EAAQC,UAAW,GAAIC,WAAYhC,GAAM,CAAE8B,QAAS,CAC/FQ,SAAUF,EAAEC,YAAYE,QAAUH,EAAEC,YAAYG,MAAQ,GAAKxC,EAAEwC,MAC/DC,SAAUL,EAAEC,YAAYK,QAAUN,EAAEC,YAAYM,OAAS,GAAK3C,EAAE2C,OAChEH,MAAOJ,EAAEC,YAAYG,MAAQxC,EAAEwC,MAC/BG,OAAQP,EAAEC,YAAYM,OAAS3C,EAAE2C,QAChCZ,UAAW,GAAIC,WAAYhC,EAChC,E","sources":["webpack://vue-vital-sign-app/./node_modules/ts-vital-sign-camera/dist/MPVisionFaceDetector-d2725298.js"],"sourcesContent":["var r = Object.defineProperty;\nvar c = (i, t, e) => t in i ? r(i, t, { enumerable: !0, configurable: !0, writable: !0, value: e }) : i[t] = e;\nvar a = (i, t, e) => (c(i, typeof t != \"symbol\" ? t + \"\" : t, e), e);\nimport * as s from \"@mediapipe/tasks-vision\";\nimport { l as d, t as l } from \"./index-09a06e31.js\";\nimport \"@mediapipe/face_mesh\";\nimport \"@mediapipe/drawing_utils\";\nclass p {\n  constructor() {\n    a(this, \"faceDetector\");\n    a(this, \"runningMode\", \"IMAGE\");\n    a(this, \"modelLocation\", \"CDN\");\n    console.log(\"[MPFaceDetector] Created.\");\n  }\n  get modelAssetPath() {\n    if (this.modelLocation === \"CDN\")\n      return \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\";\n    {\n      const { protocol: t, host: e } = window.location;\n      return `${t}//${e}/models/mpvision/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`;\n    }\n  }\n  async initializefaceDetector() {\n    const t = await s.FilesetResolver.forVisionTasks(\n      \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n    );\n    this.faceDetector = await s.FaceDetector.createFromOptions(t, {\n      baseOptions: {\n        modelAssetPath: this.modelAssetPath,\n        delegate: \"GPU\"\n      },\n      runningMode: this.runningMode\n    });\n  }\n  async loadModels() {\n    await this.initializefaceDetector();\n    const t = await d();\n    await this.detect({ image: t });\n  }\n  async detect(t) {\n    const e = l(t);\n    if (this.faceDetector === void 0)\n      return { faceBox: void 0, landmarks: [], videoFrame: e };\n    const n = this.faceDetector.detect(e).detections;\n    if (n.length === 0)\n      return { faceBox: void 0, landmarks: [], videoFrame: e };\n    const o = n[0];\n    return o.boundingBox === void 0 ? { faceBox: void 0, landmarks: [], videoFrame: e } : { faceBox: {\n      xCenter: (o.boundingBox.originX + o.boundingBox.width / 2) / e.width,\n      yCenter: (o.boundingBox.originY + o.boundingBox.height / 2) / e.height,\n      width: o.boundingBox.width / e.width,\n      height: o.boundingBox.height / e.height\n    }, landmarks: [], videoFrame: e };\n  }\n}\nexport {\n  p as MPVisionFaceDetector\n};\n"],"names":["r","Object","defineProperty","c","i","t","e","enumerable","configurable","writable","value","a","p","constructor","this","console","log","modelAssetPath","modelLocation","protocol","host","window","location","initializefaceDetector","s","forVisionTasks","faceDetector","createFromOptions","baseOptions","delegate","runningMode","loadModels","d","detect","image","l","faceBox","landmarks","videoFrame","n","detections","length","o","boundingBox","xCenter","originX","width","yCenter","originY","height"],"sourceRoot":""}